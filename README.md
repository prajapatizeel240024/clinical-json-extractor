# ðŸ©ºâ€¯Clinicalâ€‘JSONâ€‘Extractor

Extract structured clinical data from scannedâ€¯(or bornâ€‘digital) PDFs by pairing  
**PyMuPDF** for rasterisation with **GPTâ€‘4oâ€¯Vision** for two LLM steps:

1. **Extraction** â€“ pageâ€‘wise OCRâ€¯+â€¯field parsing  
2. **Transformation** â€“ conform raw output to your JSON schema

> **Quick demo:** a 3â€‘page PDF of medical notes is converted to  
> `transformed_attention_extracted.json` in â‰²â€¯25â€¯s and costs **â‰ˆâ€¯$0.10â€¯USD**.

---

## ðŸ“‚â€¯Folder layout

```
clinical-json-extractor/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ extractor.py          # â† main script
â””â”€â”€ data/
    â”œâ”€â”€ attention.pdf     # sample input
    â”œâ”€â”€ medical_schema.json
    â”œâ”€â”€ extracted_medical.json/      # autoâ€‘created
    â””â”€â”€ final_medical.json/          # autoâ€‘created
```

*Feel free to rename `extractor.py`; just update the commands below.*

---

## âš™ï¸â€¯Setup

```bash
# 1) clone / copy repo
cd clinical-json-extractor

# 2) create Python â‰¥3.10 environment
python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate

# 3) install dependencies
pip install -r requirements.txt

# 4) add your OpenAI key (bash)
export OPENAI_API_KEY="sk-..."   # PowerShell: setx OPENAI_API_KEY "sk-..."
```

---

## â–¶ï¸â€¯Running

```bash
# Drop PDFs (and optionally their schemas) into ./data
python extractor.py
```

### Optional tweaks  
All constantsâ€”paths, model name, DPIâ€”sit near the top of `extractor.py`.  
Edit them to point at different folders, files, or model versions.

---

## ðŸŒâ€¯Architecture overview

```mermaid
flowchart TD
  %% â”€â”€ 1. Preâ€‘processing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  subgraph "Preâ€‘processing"
    A[PDF] -->|PyMuPDF â€“ rasterise @â€¯200â€¯DPI| B[Baseâ€‘64 PNGs]
  end

  %% â”€â”€ 2. LLM Extraction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  subgraph "LLM Extraction"
    B -->|GPTâ€‘4o Vision (promptÂ #1)| C[Pageâ€‘level JSON]
    C -->|append| D[Raw JSON list]
  end

  %% â”€â”€ 3. LLM Transformation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  subgraph "LLM Transformation"
    D -->|GPTâ€‘4oÂ (promptÂ #2)| E[Schemaâ€‘compliant JSON]
  end

  %% â”€â”€ 4. Persistence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  subgraph Persistence
    E -->|write file| F[(data/final_*.json)]
  end

  %% annotation
  classDef faint fill=#0000,stroke-width:0,color=#999;
  class B,C,D,E faint;
```

*Only the â€œLLM Extractionâ€ and â€œLLM Transformationâ€ steps hit the OpenAI API.*

---

## ðŸ’°â€¯Cost cheatâ€‘sheet (GPTâ€‘4oÂ Aprâ€¯2025 pricing)

| Step            | Calls | Est. tokens /â€¯call* | Price /â€¯1MÂ tokens | Cost |
|-----------------|-------|---------------------|-------------------|------|
| Extraction      | 3 pages Ã—â€¯1 | ~450â€¯in +â€¯150â€¯out | \$5â€¯in / \$15â€¯out | \$0.08 |
| Transformation  | 1           | ~1â€¯000â€¯in +â€¯300â€¯out | â€³ | \$0.02 |
| **Total**       | â€”     | â€”                   | â€”                 | **â‰ˆâ€¯\$0.10** |

\*Assumes 300â€¯Ã—â€¯400â€¯px page images and compact JSON output.  
Lower DPI or shorten prompts to trim spend further.

---

## ðŸ”§â€¯Troubleshooting

| Symptom                                                        | Fix |
|---------------------------------------------------------------|-----|
| `fitz.fitz.FileDataError: cannot open`                        | Check that the PDF path is correct and the file isnâ€™t encrypted |
| `openai.BadRequestError: "image too large"`                   | Reduce `dpi` in `pdf_to_base64_images` or resize the PNG before encoding |
| Empty / misâ€‘shaped fields in final JSON                       | Ensure `medical_schema.json` keys match the schema expected in `transform_medical_data` |

---

## ðŸ“â€¯requirements.txt

```text
PyMuPDF==1.24.5
openai==1.25.1
python-dotenv==1.0.1   # optional but handy
# If you want to pin transitive deps:
pillow>=10.0.0         # PyMuPDF uses Pillow internally
```

---

### How to use

1. Copy this **README.md** and the **requirements.txt** above into your repo.  
2. Ensure `extractor.py` sits next to README.md.  
3. Place PDFs and your schema JSON inside **`./data/`**.  
4. Run `python extractor.py`.  

Youâ€™ll get `extracted_*` (raw) and `transformed_*` (schemaâ€‘ready) JSON files for downstream analytics or EHR ingestion.

Happy extracting! ðŸš€
