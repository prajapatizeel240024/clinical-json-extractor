# ðŸ©ºÂ Clinicalâ€‘JSONâ€‘Extractor

Extract structured clinical data from scanned (or bornâ€‘digital) PDFs by pairing
**PyMuPDF** for rasterisation with **GPTâ€‘4o Vision** for two LLM steps:

1. **Extraction** â€“ pageâ€‘wise OCR + field parsing  
2. **Transformation** â€“ conform raw output to your own JSON schema

> **QuickÂ demo:** a 3â€‘page PDF containing medical notes is converted into  
> `transformed_attention_extracted.json` in â‰²Â 25Â s and costs **â‰ˆÂ $0.10 USD**.

---

## ðŸ“‚Â Folder layout

```
clinical-json-extractor/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ extractor.py          # â† code you pasted
â””â”€â”€ data/                 # default data bucket
    â”œâ”€â”€ attention.pdf     # sample input
    â”œâ”€â”€ medical_schema.json
    â”œâ”€â”€ extracted_medical.json/      # autoâ€‘created
    â””â”€â”€ final_medical.json/          # autoâ€‘created
```

*Feel free to rename `extractor.py`; just update the README commands.*

---

## âš™ï¸Â Setup

```bash
# 1) clone / copy repo
cd clinical-json-extractor

# 2) create Python â‰¥3.10 environment
python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate

# 3) install deps
pip install -r requirements.txt

# 4) add your OpenAI key
export OPENAI_API_KEY="skâ€‘..."    # Windows (PowerShell): setx OPENAI_API_KEY "skâ€‘..."
```

---

## â–¶ï¸Â Running

```bash
# Drop your PDFs (and optionally their schemas) into ./data
python extractor.py
```

### Optional arguments  
The script keeps all constants near the top; edit them to point at different
folders, filenames, or model versions.

---

## ðŸŒÂ Architecture overview

```mermaid
flowchart TD
  subgraph 1[Preâ€‘processing]
    A[PDF] -->|PyMuPDF<br>rasterise @ 200Â DPI| B[Baseâ€‘64 PNGs]
  end
  subgraph 2[LLM Extraction]
    B -->|GPTâ€‘4o Vision<br>(systemÂ promptÂ #1)| C[Pageâ€‘level JSON[]]
    C -. list append .-> D[Raw JSON list]
  end
  subgraph 3[LLM Transformation]
    D -->|GPTâ€‘4o<br>(systemÂ promptÂ #2)| E[Schemaâ€‘compliant JSON]
  end
  subgraph 4[Persistence]
    E -->|write file| F[(data/final_*.json)]
  end
```

*Nodes **2** and **3** are the only parts hitting the OpenAI API.*

---

## ðŸ’°Â Cost cheatâ€‘sheet (GPTâ€‘4oÂ AprÂ 2025 pricing)

| Step | Requests | Est. tokens/request* | Price /Â 1MÂ tokens | Cost |
|------|----------|----------------------|-------------------|------|
| Extraction | 3Â pages Ã—Â 1 call | ~450 in +Â 150 out | \$5 in / \$15 out | \$0.08 |
| Transformation | 1 call | ~1Â 000 in +Â 300 out | '' | \$0.02 |
| **Total** | â€“ | â€“ | â€“ | **â‰ˆÂ \$0.10** |

\*Assumes 300Ã—400Â px page images and modest JSON output.  
Tune DPI & prompt length to control spend.

---

## ðŸ”§Â Troubleshooting

| Symptom | Fix |
|---------|-----|
| `fitz.fitz.FileDataError: cannot open` | Ensure the PDF path is correct and not encrypted |
| `openai.BadRequestError: â€œdetailâ€: â€œimage too largeâ€` | Lower `dpi` in `pdf_to_base64_images` or resize PNG before encoding |
| Empty fields in final JSON | Validate `medical_schema.json` keys exactly match what you expect |

---

## ðŸ“Â requirements.txt
```text
PyMuPDF==1.24.5
openai==1.25.1
python-dotenv==1.0.1   # optional but handy
# If you want to pin transitive deps:
pillow>=10.0.0         # PyMuPDF uses Pillow internally
```

Happy extracting! Feel free to raise issues or PRs for enhancements ðŸš€
```

---

### How to use  

1. Copy the **README.md** and **requirements.txt** blocks above into your repo.  
2. Make sure your `extractor.py` lives next to README.md.  
3. Put PDFs and your schema JSON into **`./data/`**.  
4. `python extractor.py` â€“ done!  

Youâ€™ll end up with `extracted_*` (raw) and `transformed_*` (schemaâ€‘ready) JSON
files ready for downstream analytics or EHR ingestion.
